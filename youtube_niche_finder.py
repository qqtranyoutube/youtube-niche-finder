import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
from urllib.parse import quote
from pytrends.request import TrendReq
import matplotlib.pyplot as plt
import json

st.set_page_config(page_title="YouTube Niche Finder", layout="wide")

st.title("ğŸ” YouTube Niche Finder (Advanced)")
st.markdown("TÃ¬m kiáº¿m tá»« khÃ³a YouTube Ä‘ang tÄƒng trÆ°á»Ÿng dá»±a trÃªn chá»§ Ä‘á» hoáº·c xu hÆ°á»›ng theo tá»«ng khu vá»±c.")

# --- FUNCTION: Get YouTube keyword suggestions
@st.cache_data
def get_keyword_suggestions(query):
    url = f"http://suggestqueries.google.com/complete/search?client=firefox&ds=yt&q={quote(query)}"
    headers = {"User-Agent": "Mozilla/5.0"}
    r = requests.get(url, headers=headers)
    if r.status_code == 200:
        return r.json()[1]
    else:
        return []

# --- FUNCTION: Get Google Trends by region
@st.cache_data
def get_trending_today(region_code='united_states'):
    pytrends = TrendReq(hl='en-US', tz=360)
    try:
        df = pytrends.trending_searches(pn=region_code)
        return df[0].tolist()
    except Exception:
        return []

# --- FUNCTION: Scrape YouTube results
def get_video_data(keyword, max_results=5):
    search_url = f"https://www.youtube.com/results?search_query={quote(keyword)}"
    headers = {"User-Agent": "Mozilla/5.0"}
    r = requests.get(search_url, headers=headers)
    soup = BeautifulSoup(r.text, "html.parser")
    scripts = soup.find_all("script")

    for script in scripts:
        if 'var ytInitialData' in script.text:
            raw_json = script.text.strip().split(' = ', 1)[1].rsplit(";", 1)[0]
            break
    else:
        return []

    try:
        data = json.loads(raw_json)
        items = data['contents']['twoColumnSearchResultsRenderer']['primaryContents']['sectionListRenderer']['contents'][0]['itemSectionRenderer']['contents']
    except:
        return []

    results = []
    for item in items:
        video = item.get("videoRenderer")
        if not video:
            continue
        title = video['title']['runs'][0]['text']
        views_text = video.get("viewCountText", {}).get("simpleText", "0 views")
        published = video.get("publishedTimeText", {}).get("simpleText", "N/A")
        video_id = video["videoId"]
        link = f"https://www.youtube.com/watch?v={video_id}"
        results.append({
            "Keyword": keyword,
            "Title": title,
            "Views": views_text,
            "Published": published,
            "Link": link
        })
        if len(results) >= max_results:
            break
    return results

# --- FUNCTION: Convert view text to number
def parse_views(view_text):
    try:
        if "N/A" in view_text:
            return 0
        view_text = view_text.lower().replace("views", "").strip()
        if "tr" in view_text:
            return float(view_text.replace("tr", "").strip()) * 1_000_000
        elif "k" in view_text:
            return float(view_text.replace("k", "").strip()) * 1_000
        else:
            return int(view_text.replace(",", ""))
    except:
        return 0

# --- UI: Select input method
option = st.radio("ğŸ“¥ Chá»n nguá»“n tá»« khÃ³a", ["Nháº­p chá»§ Ä‘á» thá»§ cÃ´ng", "Tá»« Google Trends"])

if option == "Nháº­p chá»§ Ä‘á» thá»§ cÃ´ng":
    topic = st.text_input("ğŸ¯ Nháº­p chá»§ Ä‘á» (vÃ­ dá»¥: ai, crypto, fitness)", value="ai")
    suggestions = get_keyword_suggestions(topic)
else:
    region_map = {
        "ğŸ‡ºğŸ‡¸ United States": "united_states",
        "ğŸ‡¬ğŸ‡§ United Kingdom": "united_kingdom",
        "ğŸ‡ªğŸ‡º European Union": "europe",
        "ğŸ‡¦ğŸ‡º Australia": "australia",
        "ğŸ‡»ğŸ‡³ Vietnam": "vietnam"
    }
    region = st.selectbox("ğŸŒ Chá»n khu vá»±c", list(region_map.keys()))
    region_code = region_map[region]
    st.info(f"ğŸ“ˆ Láº¥y tá»« khÃ³a Ä‘ang trending táº¡i {region}...")
    trending_keywords = get_trending_today(region_code)
    topic = f"Google Trends - {region}"
    suggestions = trending_keywords[:10]

# --- Advanced options
if suggestions:
    st.subheader("âš™ï¸ Tuá»³ chá»n nÃ¢ng cao")
    num_keywords = st.slider("Sá»‘ lÆ°á»£ng tá»« khÃ³a muá»‘n phÃ¢n tÃ­ch", min_value=1, max_value=len(suggestions), value=min(5, len(suggestions)))
    num_videos = st.slider("Sá»‘ video tá»‘i Ä‘a má»—i tá»« khÃ³a", min_value=1, max_value=20, value=10)

    if num_keywords * num_videos > 100:
        st.warning("âš ï¸ Báº¡n Ä‘ang táº£i ráº¥t nhiá»u dá»¯ liá»‡u. Äiá»u nÃ y cÃ³ thá»ƒ khiáº¿n á»©ng dá»¥ng cháº¡y cháº­m.")

    st.subheader("ğŸ“Œ Tá»« khÃ³a Ä‘Æ°á»£c Ä‘á» xuáº¥t")
    st.write(", ".join(suggestions[:num_keywords]))

    st.subheader("ğŸ“º PhÃ¢n tÃ­ch cÃ¡c video liÃªn quan")
    all_results = []
    for kw in suggestions[:num_keywords]:
        with st.spinner(f"ğŸ” Äang tÃ¬m video cho tá»« khÃ³a: {kw}"):
            videos = get_video_data(kw, max_results=num_videos)
        all_results.extend(videos)

    if all_results:
        df = pd.DataFrame(all_results)
        df["ParsedViews"] = df["Views"].apply(parse_views)
        df["Published"] = df["Published"].fillna("N/A")

        st.dataframe(df.drop(columns=["ParsedViews"]), use_container_width=True)

        # --- Chart
        st.subheader("ğŸ“Š Biá»ƒu Ä‘á»“ lÆ°á»£t xem trung bÃ¬nh theo tá»« khÃ³a")
        chart_df = df.groupby("Keyword")["ParsedViews"].mean().sort_values(ascending=False)
        st.bar_chart(chart_df)

        # --- Download CSV
        csv = df.drop(columns=["ParsedViews"]).to_csv(index=False).encode("utf-8")
        st.download_button("â¬‡ï¸ Táº£i káº¿t quáº£ CSV", data=csv, file_name="youtube_niche_results.csv", mime="text/csv")
    else:
        st.info("âš ï¸ KhÃ´ng tÃ¬m tháº¥y video phÃ¹ há»£p.")
else:
    st.warning("â— KhÃ´ng tÃ¬m tháº¥y tá»« khÃ³a nÃ o.")
